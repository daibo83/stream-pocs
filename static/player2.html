<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Video Player</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
            background-color: #f0f0f0;
        }
        #videoPlayer {
            max-width: 640px;
            width: 100%;
            margin-bottom: 20px;
        }
        #status {
            font-weight: bold;
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <canvas id="canvas" width="640" height="480"></canvas>
    <!-- <video id="videoPlayer" autoplay controls></video> -->
    <button id="startButton">Start Playing</button>
    <div id="status">Not connected</div>
    <script src="https://rawgithub.com/kawanet/msgpack-lite/master/dist/msgpack.min.js"></script>

    <script>
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        let pendingFrames = [];
        let underflow = true;
        let baseTime = 0;
        function handleFrame(frame) {
            pendingFrames.push(frame);
            if (underflow) setTimeout(renderFrame, 0);
        }
        function calculateTimeUntilNextFrame(timestamp) {
            if (baseTime == 0) baseTime = performance.now();
            let mediaTime = performance.now() - baseTime;
            return Math.max(0, timestamp / 1000 - mediaTime);
        }


        async function renderFrame() {
            underflow = pendingFrames.length == 0;
            if (underflow) return;

            const frame = pendingFrames.shift();

            // Based on the frame's timestamp calculate how much of real time waiting
            // is needed before showing the next frame.
            const timeUntilNextFrame = calculateTimeUntilNextFrame(frame.timestamp);
            await new Promise((r) => {
                setTimeout(r, timeUntilNextFrame);
            });
            var aspectRatio = frame.codedWidth / frame.codedHeight;
            canvas.width = window.innerWidth;
            canvas.height = window.innerWidth / aspectRatio;
            ctx.drawImage(frame, 0, 0, canvas.width, canvas.height);
            frame.close();

            // Immediately schedule rendering of the next frame
            setTimeout(renderFrame, 0);
        }

        const statusDiv = document.getElementById('status');        
        const startButton = document.getElementById('startButton');
        const websocketUrl = `wss://${window.location.host}/consume/test_stream`;
        const init = {
            output: handleFrame,
            error: (e) => {
                console.log(e.message);
            },
        };
        // let description_array = new Uint8Array(([1, 1, 96, 0, 0, 0, 176, 0, 0, 0, 0, 0, 123, 240, 0, 252, 253, 248, 248, 0, 0, 15, 3, 160, 0, 1, 0, 24, 64, 1, 12, 1, 255, 255, 1, 96, 0, 0, 3, 0, 176, 0, 0, 3, 0, 0, 3, 0, 123, 27, 2, 64, 161, 0, 1, 0, 47, 66, 1, 1, 1, 96, 0, 0, 3, 0, 176, 0, 0, 3, 0, 0, 3, 0, 123, 160, 3, 192, 128, 17, 7, 203, 136, 27, 185, 20, 140, 185, 248, 79, 66, 250, 134, 245, 74, 106, 2, 2, 3, 108, 31, 194, 1, 4, 162, 0, 1, 0, 7, 68, 1, 192, 114, 240, 91, 36]));
        // let arraybuffer = new ArrayBuffer(description_array.length);
        // arraybuffer = description_array.buffer;
        // console.log(arraybuffer);
        const config = {
            // codec: "avc1.640c34",
            codec: "hev1.1.0.L30.b0",
            // description: arraybuffer,
            codedHeight: 1080,
            codedWidth: 1920,
            colorSpace: {
                fullRange: false,
                matrix: "bt709",
                primaries: "bt709",
                transfer: "bt709"
            },
            hardwareAcceleration: "no-preference",
            // optimizeForLatency: true,
        }
        // config.avc = { 
        //     format: "annexb",
        //     maxBFrames: 0,
        // };
        let mediaSource;
        let sourceBuffer;
        let websocket;
        let queue = [];
        let isBufferUpdating = false;
        let decoder;

        async function startPlaying(){
            const { supported } = await VideoDecoder.isConfigSupported(config);
            if (supported) {
                decoder = new VideoDecoder(init);
                decoder.configure(config);
            } else {
                console.log('Configuration not supported');
            }
            websocket = new WebSocket(websocketUrl);
            websocket.binaryType ="arraybuffer";
            websocket.onopen = () => {
                statusDiv.textContent = 'Connected';
            };
            var description_received = false;
            websocket.onmessage = (event) => {
                if (!description_received) {
                    description_received = true;
                    config.description = event.data;
                    decoder.configure(config);
                    return;
                }
                const chunk = new EncodedVideoChunk({
                    timestamp: 0,
                    type: "key",
                    data: event.data,
                });
                if (decoder.state == "closed") {
                    decoder = new VideoDecoder(init);
                    decoder.configure(config);
                }
                try {
                    decoder.decode(chunk);
                } catch (error) {
                    console.log("handle error", error);
                }
            };
            await decoder.flush();
        }
        startButton.addEventListener('click', startPlaying);
    </script>
</body>
</html>