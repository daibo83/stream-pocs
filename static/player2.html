<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Video Player</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
            background-color: #f0f0f0;
        }

        #videoPlayer {
            max-width: 640px;
            width: 100%;
            margin-bottom: 20px;
        }

        #status {
            font-weight: bold;
            margin-top: 20px;
        }
    </style>
</head>

<body>

    <video id="videoPlayer" autoplay muted></video>
    <button id="startButton">Start Playing</button>
    <div id="status">Not connected</div>
    <script src="MSTG_polyfill.js"></script>
    <script>
        let pendingFrames = [];
        let underflow = true;
        let baseTime = 0;
        let writer;
        let trackGenerator;
        let videoStream;
        const videoElement = document.getElementById('videoPlayer');
        if (typeof MediaStreamTrackGenerator === "undefined") {
            trackGenerator = new VideoTrackGenerator();
            videoStream = new MediaStream([trackGenerator.track]);
            videoElement.srcObject = videoStream;
            writer = trackGenerator.writable.getWriter();
        }
        else {
            trackGenerator = new MediaStreamTrackGenerator({ kind: "video" });
            videoStream = new MediaStream([trackGenerator]);
            videoElement.srcObject = videoStream;
            writer = trackGenerator.writable.getWriter();
        }
        function handleFrame(frame) {
            // pendingFrames.push(frame);
            writer.write(frame);
            // if (underflow) setTimeout(renderFrame, 0);
        }
        function calculateTimeUntilNextFrame(timestamp) {
            if (baseTime == 0) baseTime = performance.now();
            let mediaTime = performance.now() - baseTime;
            return Math.max(0, timestamp / 1000 - mediaTime);
        }


        async function renderFrame() {
            underflow = pendingFrames.length == 0;
            if (underflow) return;

            const frame = pendingFrames.shift();

            // Based on the frame's timestamp calculate how much of real time waiting
            // is needed before showing the next frame.
            const timeUntilNextFrame = calculateTimeUntilNextFrame(frame.timestamp);
            await new Promise((r) => {
                setTimeout(r, timeUntilNextFrame);
            });
            var aspectRatio = frame.codedWidth / frame.codedHeight;
            canvas.width = window.innerWidth;
            canvas.height = window.innerWidth / aspectRatio;
            ctx.drawImage(frame, 0, 0, canvas.width, canvas.height);
            frame.close();

            // Immediately schedule rendering of the next frame
            setTimeout(renderFrame, 0);
        }

        const statusDiv = document.getElementById('status');
        const startButton = document.getElementById('startButton');
        const websocketUrl = `wss://${window.location.host}/consume/test_stream`;
        const init = {
            output: handleFrame,
            error: (e) => {
                console.log(e.message);
            },
        };
        let config;
        let mediaSource;
        let sourceBuffer;
        let websocket;
        let queue = [];
        let isBufferUpdating = false;
        let decoder;

        async function startPlaying() {
            decoder = new VideoDecoder(init);
            websocket = new WebSocket(websocketUrl);
            websocket.binaryType = "arraybuffer";
            websocket.onopen = () => {
                statusDiv.textContent = 'Connected';
            };
            var config_received = false;
            websocket.onmessage = (event) => {
                if (!config_received) {
                    let dataview = new DataView(event.data);
                    let jsonlength = dataview.getUint16(0);
                    let textDecoder = new TextDecoder();
                    let jsonbytes = event.data.slice(2, jsonlength + 2);
                    let jsonstring = textDecoder.decode(jsonbytes);
                    config = JSON.parse(jsonstring);
                    let description = event.data.slice(jsonlength + 2);
                    config.description = description;
                    console.log("config", config);
                    config_received = true;
                    decoder.configure(config);
                    return;
                }
                let dataview = new DataView(event.data);
                let timestamp = dataview.getUint32(0);
                const chunk = new EncodedVideoChunk({
                    timestamp,
                    type: "key",
                    data: event.data.slice(4),
                });
                if (decoder.state == "closed") {
                    decoder = new VideoDecoder(init);
                    decoder.configure(config);
                }
                try {
                    decoder.decode(chunk);
                } catch (error) {
                    console.log("handle error", error);
                }
            };
            await decoder.flush();
        }
        startButton.addEventListener('click', startPlaying);
    </script>
</body>

</html>